{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install datasets transformers evaluate jiwer -q","metadata":{"execution":{"iopub.status.busy":"2024-11-16T04:31:24.414527Z","iopub.execute_input":"2024-11-16T04:31:24.414952Z","iopub.status.idle":"2024-11-16T04:31:39.188415Z","shell.execute_reply.started":"2024-11-16T04:31:24.414910Z","shell.execute_reply":"2024-11-16T04:31:39.187257Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport datasets\nfrom datasets import Audio\nimport evaluate\nimport numpy as np\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\nfrom transformers import WhisperTokenizer\nfrom transformers import WhisperFeatureExtractor\nfrom transformers import WhisperProcessor\nfrom transformers import WhisperForConditionalGeneration\nfrom transformers import Seq2SeqTrainingArguments\n\nfrom transformers import AutoModelForCTC\nfrom transformers import TrainingArguments\nfrom transformers import Trainer","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:12.957871Z","iopub.execute_input":"2024-11-16T05:17:12.958636Z","iopub.status.idle":"2024-11-16T05:17:13.454371Z","shell.execute_reply.started":"2024-11-16T05:17:12.958593Z","shell.execute_reply":"2024-11-16T05:17:13.453526Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"ds = datasets.load_dataset(\"mozilla-foundation/common_voice_11_0\", \n                           name=\"as\", \n                           split=\"train+test\")","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:13.456018Z","iopub.execute_input":"2024-11-16T05:17:13.456350Z","iopub.status.idle":"2024-11-16T05:17:14.436170Z","shell.execute_reply.started":"2024-11-16T05:17:13.456315Z","shell.execute_reply":"2024-11-16T05:17:14.435143Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:14.438152Z","iopub.execute_input":"2024-11-16T05:17:14.438597Z","iopub.status.idle":"2024-11-16T05:17:14.451890Z","shell.execute_reply.started":"2024-11-16T05:17:14.438559Z","shell.execute_reply":"2024-11-16T05:17:14.450487Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model_path=\"openai/whisper-tiny\"","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:14.453066Z","iopub.execute_input":"2024-11-16T05:17:14.453407Z","iopub.status.idle":"2024-11-16T05:17:14.459259Z","shell.execute_reply.started":"2024-11-16T05:17:14.453372Z","shell.execute_reply":"2024-11-16T05:17:14.458397Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"feature_extractor = WhisperFeatureExtractor.from_pretrained(model_path)\ntokenizer = WhisperTokenizer.from_pretrained(model_path, language=\"Assamese\", task=\"transcribe\")\nprocessor = WhisperProcessor.from_pretrained(model_path, language=\"Assamese\", task=\"transcribe\")","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:14.461618Z","iopub.execute_input":"2024-11-16T05:17:14.462071Z","iopub.status.idle":"2024-11-16T05:17:15.692295Z","shell.execute_reply.started":"2024-11-16T05:17:14.462018Z","shell.execute_reply":"2024-11-16T05:17:15.691476Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"s1 = ds[0]\ns1","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:15.693441Z","iopub.execute_input":"2024-11-16T05:17:15.693767Z","iopub.status.idle":"2024-11-16T05:17:17.179535Z","shell.execute_reply.started":"2024-11-16T05:17:15.693733Z","shell.execute_reply":"2024-11-16T05:17:17.178519Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'client_id': 'af73187438537bf78a33930717694a696d489072f8e334e9a21dd46fa09ae9c3040e4d44e97e8c2bea2bfda5d74e73063f486d36ca84f4bfc56b43a58bb9389b',\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/fdcfd174c1db561f74a5aab292ff32458ceffd67c10de1ac5f5b77eae211090c/as_train_0/common_voice_as_22074894.mp3',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/fdcfd174c1db561f74a5aab292ff32458ceffd67c10de1ac5f5b77eae211090c/as_train_0/common_voice_as_22074894.mp3',\n  'array': array([ 5.29395592e-23, -6.61744490e-23,  1.48892510e-22, ...,\n          1.20360312e-07, -1.29233990e-06, -1.51768404e-06]),\n  'sampling_rate': 16000},\n 'sentence': 'দেখিলে যে অসমীয়া মানুহৰ জ্ঞান-উন্নতি পিনে অলপাে মনকাণ নাই',\n 'up_votes': 2,\n 'down_votes': 0,\n 'age': '',\n 'gender': '',\n 'accent': '',\n 'locale': 'as',\n 'segment': ''}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def prepare_dataset(batch):\n    # load and resample audio data from 48 to 16kHz\n    audio = batch[\"audio\"]\n\n    # compute log-Mel input features from input audio array \n    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n    # compute input length of audio sample in seconds\n    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n    # encode target text to label ids \n    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:17.181081Z","iopub.execute_input":"2024-11-16T05:17:17.182135Z","iopub.status.idle":"2024-11-16T05:17:17.188809Z","shell.execute_reply.started":"2024-11-16T05:17:17.182078Z","shell.execute_reply":"2024-11-16T05:17:17.187682Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# tokenizer(s1[\"sentence\"])\n# feature_extractor(s1[\"audio\"][\"array\"], sampling_rate=s1[\"audio\"][\"sampling_rate\"]).input_features[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:17.191074Z","iopub.execute_input":"2024-11-16T05:17:17.191478Z","iopub.status.idle":"2024-11-16T05:17:17.197692Z","shell.execute_reply.started":"2024-11-16T05:17:17.191443Z","shell.execute_reply":"2024-11-16T05:17:17.196849Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"cvds = ds.map(prepare_dataset, remove_columns=ds.column_names, num_proc=4)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:17.198658Z","iopub.execute_input":"2024-11-16T05:17:17.198991Z","iopub.status.idle":"2024-11-16T05:17:19.914319Z","shell.execute_reply.started":"2024-11-16T05:17:17.198957Z","shell.execute_reply":"2024-11-16T05:17:19.913210Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"test_set = cvds.select(range(10))\ntrain_set = cvds.select(range(10, len(cvds)))","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:19.915807Z","iopub.execute_input":"2024-11-16T05:17:19.916204Z","iopub.status.idle":"2024-11-16T05:17:19.928746Z","shell.execute_reply.started":"2024-11-16T05:17:19.916158Z","shell.execute_reply":"2024-11-16T05:17:19.928004Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_set, test_set","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:17:19.929897Z","iopub.execute_input":"2024-11-16T05:17:19.930211Z","iopub.status.idle":"2024-11-16T05:17:19.936366Z","shell.execute_reply.started":"2024-11-16T05:17:19.930178Z","shell.execute_reply":"2024-11-16T05:17:19.935477Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['input_features', 'input_length', 'labels'],\n     num_rows: 1122\n }),\n Dataset({\n     features: ['input_features', 'input_length', 'labels'],\n     num_rows: 10\n }))"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:56.444437Z","iopub.execute_input":"2024-11-16T05:48:56.444847Z","iopub.status.idle":"2024-11-16T05:48:56.733786Z","shell.execute_reply.started":"2024-11-16T05:48:56.444809Z","shell.execute_reply":"2024-11-16T05:48:56.732820Z"},"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# forced decoder ids to none\nmodel.generation_config.language = \"assamese\"\nmodel.generation_config.task = \"transcribe\"\n\nmodel.generation_config.forced_decoder_ids = None\nmodel.config.forced_decoder_ids = None\n# set language to assamese, task to asr","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:57.130450Z","iopub.execute_input":"2024-11-16T05:48:57.130811Z","iopub.status.idle":"2024-11-16T05:48:57.135775Z","shell.execute_reply.started":"2024-11-16T05:48:57.130774Z","shell.execute_reply":"2024-11-16T05:48:57.134669Z"},"trusted":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:57.753983Z","iopub.execute_input":"2024-11-16T05:48:57.754356Z","iopub.status.idle":"2024-11-16T05:48:57.763676Z","shell.execute_reply.started":"2024-11-16T05:48:57.754319Z","shell.execute_reply":"2024-11-16T05:48:57.762620Z"},"trusted":true},"outputs":[],"execution_count":50},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:58.948334Z","iopub.execute_input":"2024-11-16T05:48:58.948741Z","iopub.status.idle":"2024-11-16T05:48:58.953262Z","shell.execute_reply.started":"2024-11-16T05:48:58.948701Z","shell.execute_reply":"2024-11-16T05:48:58.952323Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"model.config.decoder_start_token_id","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:58.955316Z","iopub.execute_input":"2024-11-16T05:48:58.955974Z","iopub.status.idle":"2024-11-16T05:48:58.966111Z","shell.execute_reply.started":"2024-11-16T05:48:58.955926Z","shell.execute_reply":"2024-11-16T05:48:58.965300Z"},"trusted":true},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"50258"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"# data_collator(test_set.select(range(2)))?","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:59.283825Z","iopub.execute_input":"2024-11-16T05:48:59.284487Z","iopub.status.idle":"2024-11-16T05:48:59.287957Z","shell.execute_reply.started":"2024-11-16T05:48:59.284451Z","shell.execute_reply":"2024-11-16T05:48:59.287038Z"},"trusted":true},"outputs":[],"execution_count":53},{"cell_type":"code","source":"wer_metric = evaluate.load(\"wer\")","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:48:59.688995Z","iopub.execute_input":"2024-11-16T05:48:59.689584Z","iopub.status.idle":"2024-11-16T05:49:00.013759Z","shell.execute_reply.started":"2024-11-16T05:48:59.689548Z","shell.execute_reply":"2024-11-16T05:49:00.012966Z"},"trusted":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def compute_metric(pred):\n#     pred_logits = pred.predictions\n#     pred_ids = np.argmax(pred_logits, axis=-1)\n    pred_ids = pred.predictions\n\n    pred.label_ids[pred.label_ids==-100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n#     # we do not want to group tokens when computing the metrics\n    label_str = processor.tokenizer.batch_decode(pred.label_ids, skip_special_tokens=True)\n\n    wer = wer_metric.compute(predictions=pred_str, referecnes=label_str)\n    return {\"wer\":wer}","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:49:01.282409Z","iopub.execute_input":"2024-11-16T05:49:01.282819Z","iopub.status.idle":"2024-11-16T05:49:01.289003Z","shell.execute_reply.started":"2024-11-16T05:49:01.282781Z","shell.execute_reply":"2024-11-16T05:49:01.288092Z"},"trusted":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# from transformers import Seq2SeqTrainingArguments\n\n# training_args = Seq2SeqTrainingArguments(\n#     output_dir=\"./whisper-tiny-as\",  # change to a repo name of your choice\n#     per_device_train_batch_size=8,\n#     gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n#     learning_rate=1e-5,\n#     warmup_steps=50,\n#     max_steps=100,\n#     fp16=True,\n#     eval_strategy=\"steps\",\n#     per_device_eval_batch_size=1,\n#     predict_with_generate=True,\n#     generation_max_length=225,\n#     save_steps=100,\n#     eval_steps=100,\n#     logging_steps=25,\n#     load_best_model_at_end=True,\n#     metric_for_best_model=\"wer\",\n#     greater_is_better=False,\n# )\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:49:01.290970Z","iopub.execute_input":"2024-11-16T05:49:01.291293Z","iopub.status.idle":"2024-11-16T05:49:01.308081Z","shell.execute_reply.started":"2024-11-16T05:49:01.291237Z","shell.execute_reply":"2024-11-16T05:49:01.307182Z"},"trusted":true},"outputs":[],"execution_count":56},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-small-hi\",  # change to a repo name of your choice\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n    learning_rate=1e-5,\n    warmup_steps=50,\n    max_steps=100,\n    fp16=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=1,\n#     predict_with_generate=True,\n    save_steps=100,\n    eval_steps=100,\n    logging_steps=100,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=False,\n    report_to=\"none\",\n    label_names=[\"labels\"]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:49:01.309091Z","iopub.execute_input":"2024-11-16T05:49:01.309400Z","iopub.status.idle":"2024-11-16T05:49:01.349414Z","shell.execute_reply.started":"2024-11-16T05:49:01.309368Z","shell.execute_reply":"2024-11-16T05:49:01.348456Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model.to(\"cuda:0\"),\n    train_dataset=train_set,\n    eval_dataset=test_set,\n    data_collator=data_collator,\n    compute_metrics=compute_metric,\n    tokenizer=processor.tokenizer,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:49:01.350364Z","iopub.execute_input":"2024-11-16T05:49:01.350648Z","iopub.status.idle":"2024-11-16T05:49:01.430317Z","shell.execute_reply.started":"2024-11-16T05:49:01.350616Z","shell.execute_reply":"2024-11-16T05:49:01.429506Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-16T05:49:04.279767Z","iopub.execute_input":"2024-11-16T05:49:04.280151Z","iopub.status.idle":"2024-11-16T06:10:57.484429Z","shell.execute_reply.started":"2024-11-16T05:49:04.280115Z","shell.execute_reply":"2024-11-16T06:10:57.482827Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='101' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 05:36, Epoch 1.41/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:01]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2467\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2915\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2913\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2872\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2872\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:4160\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4156\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   4157\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   4158\u001b[0m         )\n\u001b[1;32m   4159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4160\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4162\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[0;32mIn[55], line 8\u001b[0m, in \u001b[0;36mcompute_metric\u001b[0;34m(pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m     pred_ids \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m      6\u001b[0m     pred\u001b[38;5;241m.\u001b[39mlabel_ids[pred\u001b[38;5;241m.\u001b[39mlabel_ids\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m] \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[0;32m----> 8\u001b[0m     pred_str \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     # we do not want to group tokens when computing the metrics\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     label_str \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(pred\u001b[38;5;241m.\u001b[39mlabel_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3967\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3943\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3944\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3945\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3949\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3951\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3952\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3966\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   3968\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m   3969\u001b[0m             seq,\n\u001b[1;32m   3970\u001b[0m             skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m   3971\u001b[0m             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[1;32m   3972\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3973\u001b[0m         )\n\u001b[1;32m   3974\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3975\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3968\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3943\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_decode\u001b[39m(\n\u001b[1;32m   3944\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3945\u001b[0m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3949\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m   3950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3951\u001b[0m \u001b[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[1;32m   3952\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3965\u001b[0m \u001b[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[1;32m   3966\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m-> 3968\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3974\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[1;32m   3975\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/whisper/tokenization_whisper.py:708\u001b[0m, in \u001b[0;36mWhisperTokenizer.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, output_offsets, time_precision, decode_with_timestamps, normalize, basic_normalize, remove_diacritics, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03mConverts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03mtokens and clean up tokenization spaces.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m    `str`: The decoded sentence.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m filtered_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_token_ids(\n\u001b[1;32m    704\u001b[0m     token_ids,\n\u001b[1;32m    705\u001b[0m     skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens,\n\u001b[1;32m    706\u001b[0m )\n\u001b[0;32m--> 708\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasic_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasic_normalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_diacritics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_diacritics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_with_timestamps:\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;66;03m# legacy method to decode timestamps when not included in the tokenizer vocabulary\u001b[39;00m\n\u001b[1;32m    719\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_with_timestamps(\n\u001b[1;32m    720\u001b[0m         filtered_ids, time_precision\u001b[38;5;241m=\u001b[39mtime_precision, skip_special_tokens\u001b[38;5;241m=\u001b[39mskip_special_tokens\n\u001b[1;32m    721\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4007\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4004\u001b[0m \u001b[38;5;66;03m# Convert inputs to python lists\u001b[39;00m\n\u001b[1;32m   4005\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m to_py_obj(token_ids)\n\u001b[0;32m-> 4007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4011\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4012\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/whisper/tokenization_whisper.py:741\u001b[0m, in \u001b[0;36mWhisperTokenizer._decode\u001b[0;34m(self, token_ids, skip_special_tokens, normalize, basic_normalize, remove_diacritics, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode\u001b[39m(\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    733\u001b[0m     token_ids: Union[\u001b[38;5;28mint\u001b[39m, List[\u001b[38;5;28mint\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    739\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_use_source_tokenizer \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_source_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 741\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_ids_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;66;03m# To avoid mixing byte-level and unicode for byte-level BPT\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# we need to build string separately for added tokens and byte-level tokens\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;66;03m# cf. https://github.com/huggingface/transformers/issues/1133\u001b[39;00m\n\u001b[1;32m    746\u001b[0m     sub_texts \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils.py:1063\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.convert_ids_to_tokens\u001b[0;34m(self, ids, skip_special_tokens)\u001b[0m\n\u001b[1;32m   1061\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[0;32m-> 1063\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m skip_special_tokens \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_special_ids:\n\u001b[1;32m   1065\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'list'"],"ename":"TypeError","evalue":"int() argument must be a string, a bytes-like object or a real number, not 'list'","output_type":"error"}],"execution_count":59},{"cell_type":"code","source":"dss = datasets.load_dataset(\"mozilla-foundation/common_voice_11_0\", \n                           name=\"as\",\n                            split=\"train\")\n\ndss","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:18:11.435708Z","iopub.execute_input":"2024-11-16T06:18:11.436140Z","iopub.status.idle":"2024-11-16T06:18:12.305963Z","shell.execute_reply.started":"2024-11-16T06:18:11.436099Z","shell.execute_reply":"2024-11-16T06:18:12.304954Z"},"trusted":true},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n    num_rows: 824\n})"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"#Q2: How many unique characters are there in the train split text ?\n\nsent = \" \".join(dss[\"sentence\"])","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:23.463985Z","iopub.execute_input":"2024-11-16T06:26:23.464929Z","iopub.status.idle":"2024-11-16T06:26:23.471084Z","shell.execute_reply.started":"2024-11-16T06:26:23.464881Z","shell.execute_reply":"2024-11-16T06:26:23.470170Z"},"trusted":true},"outputs":[],"execution_count":81},{"cell_type":"code","source":"# sent","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:09.038784Z","iopub.execute_input":"2024-11-16T06:26:09.039184Z","iopub.status.idle":"2024-11-16T06:26:09.043693Z","shell.execute_reply.started":"2024-11-16T06:26:09.039145Z","shell.execute_reply":"2024-11-16T06:26:09.042620Z"},"trusted":true},"outputs":[],"execution_count":77},{"cell_type":"code","source":"chars=set()","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:32.475671Z","iopub.execute_input":"2024-11-16T06:26:32.476059Z","iopub.status.idle":"2024-11-16T06:26:32.480545Z","shell.execute_reply.started":"2024-11-16T06:26:32.476021Z","shell.execute_reply":"2024-11-16T06:26:32.479499Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"code","source":"for char in sent:\n    chars.add(char)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:32.587928Z","iopub.execute_input":"2024-11-16T06:26:32.588767Z","iopub.status.idle":"2024-11-16T06:26:32.599254Z","shell.execute_reply.started":"2024-11-16T06:26:32.588730Z","shell.execute_reply":"2024-11-16T06:26:32.598293Z"},"trusted":true},"outputs":[],"execution_count":83},{"cell_type":"code","source":"len(chars)","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:32.783604Z","iopub.execute_input":"2024-11-16T06:26:32.783911Z","iopub.status.idle":"2024-11-16T06:26:32.789614Z","shell.execute_reply.started":"2024-11-16T06:26:32.783878Z","shell.execute_reply":"2024-11-16T06:26:32.788632Z"},"trusted":true},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"74"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"# 3\ndss[0][\"audio\"][\"sampling_rate\"]","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:39:35.257484Z","iopub.execute_input":"2024-11-16T06:39:35.257922Z","iopub.status.idle":"2024-11-16T06:39:35.276346Z","shell.execute_reply.started":"2024-11-16T06:39:35.257883Z","shell.execute_reply":"2024-11-16T06:39:35.275120Z"},"trusted":true},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"48000"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"# Q4\ndss[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:26:55.896909Z","iopub.execute_input":"2024-11-16T06:26:55.897851Z","iopub.status.idle":"2024-11-16T06:26:55.917077Z","shell.execute_reply.started":"2024-11-16T06:26:55.897804Z","shell.execute_reply":"2024-11-16T06:26:55.916184Z"},"trusted":true},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"{'client_id': 'af73187438537bf78a33930717694a696d489072f8e334e9a21dd46fa09ae9c3040e4d44e97e8c2bea2bfda5d74e73063f486d36ca84f4bfc56b43a58bb9389b',\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/fdcfd174c1db561f74a5aab292ff32458ceffd67c10de1ac5f5b77eae211090c/as_train_0/common_voice_as_22074894.mp3',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/fdcfd174c1db561f74a5aab292ff32458ceffd67c10de1ac5f5b77eae211090c/as_train_0/common_voice_as_22074894.mp3',\n  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n         -1.51620850e-06, -1.28747206e-06, -6.44893703e-07]),\n  'sampling_rate': 48000},\n 'sentence': 'দেখিলে যে অসমীয়া মানুহৰ জ্ঞান-উন্নতি পিনে অলপাে মনকাণ নাই',\n 'up_votes': 2,\n 'down_votes': 0,\n 'age': '',\n 'gender': '',\n 'accent': '',\n 'locale': 'as',\n 'segment': ''}"},"metadata":{}}],"execution_count":85},{"cell_type":"markdown","source":"## Q5  \n\nWhat will be the window length in msec if n fft is 400 in ”WhisperFeatureExtractor” ?\n\n![image.png](attachment:6889631a-ed19-4cbb-978b-84c4e8f20c64.png)","metadata":{},"attachments":{"6889631a-ed19-4cbb-978b-84c4e8f20c64.png":{"image/png":"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"}}},{"cell_type":"code","source":"# Q5\n400*1000/16000","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:41:13.437416Z","iopub.execute_input":"2024-11-16T06:41:13.438159Z","iopub.status.idle":"2024-11-16T06:41:13.443844Z","shell.execute_reply.started":"2024-11-16T06:41:13.438118Z","shell.execute_reply":"2024-11-16T06:41:13.442935Z"},"trusted":true},"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"25.0"},"metadata":{}}],"execution_count":87},{"cell_type":"code","source":"# Q6 : What is the first token number after tokenising the 56th example?\nprocessor.tokenizer(ds[55][\"sentence\"]).input_ids[0]","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:41:58.376459Z","iopub.execute_input":"2024-11-16T06:41:58.376838Z","iopub.status.idle":"2024-11-16T06:41:58.395227Z","shell.execute_reply.started":"2024-11-16T06:41:58.376803Z","shell.execute_reply":"2024-11-16T06:41:58.394301Z"},"trusted":true},"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"50258"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"# Q7:  What is the token corresponding to the token number 51833 in whisper?\nprocessor.tokenizer.added_tokens_decoder[51833]","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:46:37.220521Z","iopub.execute_input":"2024-11-16T06:46:37.220952Z","iopub.status.idle":"2024-11-16T06:46:37.227630Z","shell.execute_reply.started":"2024-11-16T06:46:37.220911Z","shell.execute_reply":"2024-11-16T06:46:37.226630Z"},"trusted":true},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"AddedToken(\"<|29.38|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False)"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"# #Q8 Is token number 51833 (\"<|29.38|>\") a special token?\n\"<|29.38|>\" in processor.tokenizer.all_special_tokens","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:49:01.290752Z","iopub.execute_input":"2024-11-16T06:49:01.291533Z","iopub.status.idle":"2024-11-16T06:49:01.297660Z","shell.execute_reply.started":"2024-11-16T06:49:01.291476Z","shell.execute_reply":"2024-11-16T06:49:01.296690Z"},"trusted":true},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"# Q9: What is the token corresponding to the token number 50350 in whisper?\n\nprocessor.tokenizer.added_tokens_decoder[50350]","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:49:38.452345Z","iopub.execute_input":"2024-11-16T06:49:38.453063Z","iopub.status.idle":"2024-11-16T06:49:38.459405Z","shell.execute_reply.started":"2024-11-16T06:49:38.453024Z","shell.execute_reply":"2024-11-16T06:49:38.458415Z"},"trusted":true},"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"AddedToken(\"<|as|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True)"},"metadata":{}}],"execution_count":105},{"cell_type":"code","source":"# Q10: Is token number 50350 a special token?\n\n\"<|as|>\" in processor.tokenizer.all_special_tokens","metadata":{"execution":{"iopub.status.busy":"2024-11-16T06:50:26.348147Z","iopub.execute_input":"2024-11-16T06:50:26.349153Z","iopub.status.idle":"2024-11-16T06:50:26.355114Z","shell.execute_reply.started":"2024-11-16T06:50:26.349108Z","shell.execute_reply":"2024-11-16T06:50:26.354204Z"},"trusted":true},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"https://huggingface.co/blog/fine-tune-whisper#prepare-feature-extractor-tokenizer-and-data","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}