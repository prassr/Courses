{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9821131,"sourceType":"datasetVersion","datasetId":6021979}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install speechbrain==1.0.0 -q\n! pip install faster_whisper -q\n! pip install pyannote.audio -q\n! pip install whisper -q\n! pip install datasets -q","metadata":{"id":"t0O-sbiWeITy","execution":{"iopub.status.busy":"2024-11-12T16:48:08.064195Z","iopub.execute_input":"2024-11-12T16:48:08.064575Z","iopub.status.idle":"2024-11-12T16:49:27.581336Z","shell.execute_reply.started":"2024-11-12T16:48:08.064538Z","shell.execute_reply":"2024-11-12T16:49:27.580104Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import librosa\nimport traceback\nfrom faster_whisper import WhisperModel\nimport torch\nimport datasets\nfrom pathlib import Path\nimport pandas as pd\nimport re\nimport time\nimport os\nimport numpy as np\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import KMeans\nfrom pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\nfrom pyannote.audio import Audio\nfrom pyannote.core import Segment\nimport speechbrain\nfrom scipy.spatial.distance import cdist","metadata":{"id":"N_M9CxitfJzt","execution":{"iopub.status.busy":"2024-11-12T16:49:27.583342Z","iopub.execute_input":"2024-11-12T16:49:27.583667Z","iopub.status.idle":"2024-11-12T16:49:47.481763Z","shell.execute_reply.started":"2024-11-12T16:49:27.583632Z","shell.execute_reply":"2024-11-12T16:49:47.480988Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import datetime","metadata":{"id":"g4JSnB1wRzxT","execution":{"iopub.status.busy":"2024-11-12T16:49:47.483534Z","iopub.execute_input":"2024-11-12T16:49:47.484874Z","iopub.status.idle":"2024-11-12T16:49:47.488500Z","shell.execute_reply.started":"2024-11-12T16:49:47.484836Z","shell.execute_reply":"2024-11-12T16:49:47.487650Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# UPLOAD AUDIO","metadata":{"id":"8wxWEMT8ge2t"}},{"cell_type":"code","source":"# Get the path to the audio fine\naudio_file_path=\"/kaggle/input/dlp-ga/TEST-1.mp3\"","metadata":{"id":"s17MRDhCfpbA","execution":{"iopub.status.busy":"2024-11-12T16:49:48.977462Z","iopub.execute_input":"2024-11-12T16:49:48.978335Z","iopub.status.idle":"2024-11-12T16:49:48.982191Z","shell.execute_reply.started":"2024-11-12T16:49:48.978289Z","shell.execute_reply":"2024-11-12T16:49:48.981310Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## .mp3 to .wav conversion\n\n* sample rate = 16 KHz\n* Channel -1 (mono)\n* Audio Codec = pcm_s16le","metadata":{"id":"rwOHYywig3WI"}},{"cell_type":"code","source":"# mp3 to wav conversion\n# ! ffmpeg -i \"{audio_file_path}\" -ar 16000 -ac 1 -c:a pcm_s16le \"{audio_file_path.split('/')[-1][:-4]}.wav\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjdJWD56g2Wl","outputId":"8f72f859-070a-4ab2-9e1e-68d4e7346f1f","execution":{"iopub.status.busy":"2024-11-12T16:50:10.506136Z","iopub.execute_input":"2024-11-12T16:50:10.506548Z","iopub.status.idle":"2024-11-12T16:50:10.511095Z","shell.execute_reply.started":"2024-11-12T16:50:10.506507Z","shell.execute_reply":"2024-11-12T16:50:10.510015Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# SPEAKER DIARIZATION - USING WHISPER SEGMENTS AND AGGLOMERATIVE HIERARCHICAL CLUSTERING","metadata":{"id":"tivncSLThDLA"}},{"cell_type":"code","source":"audio_file=f\"{audio_file_path.split('/')[-1][:-4]}.wav\"\naudio_file=\"/kaggle/working/TEST-1.wav\"","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:50:14.247814Z","iopub.execute_input":"2024-11-12T16:50:14.248585Z","iopub.status.idle":"2024-11-12T16:50:14.252896Z","shell.execute_reply.started":"2024-11-12T16:50:14.248544Z","shell.execute_reply":"2024-11-12T16:50:14.251908Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"whisper_models = [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n\nembedding_model=PretrainedSpeakerEmbedding(\n    \"speechbrain/spkrec-ecapa-voxceleb\",\n    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:50:15.553498Z","iopub.execute_input":"2024-11-12T16:50:15.553855Z","iopub.status.idle":"2024-11-12T16:50:17.841850Z","shell.execute_reply.started":"2024-11-12T16:50:15.553820Z","shell.execute_reply":"2024-11-12T16:50:17.840977Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"hyperparams.yaml:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ed1dee30de44d75a9adca979b937e2e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/speechbrain/utils/autocast.py:63: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"embedding_model.ckpt:   0%|          | 0.00/83.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dde47bd1fa74ce19ced46d9e02f8529"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mean_var_norm_emb.ckpt:   0%|          | 0.00/1.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"958508cd152845e1a8375a542469f27f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"classifier.ckpt:   0%|          | 0.00/5.53M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e1860fe9f744b7a1e1947a51cd9093"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"label_encoder.txt:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a018b35fe8c49e395a74d2e6e3713e9"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/speechbrain/utils/checkpoints.py:152: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(path, map_location=device), strict=False\n/opt/conda/lib/python3.10/site-packages/speechbrain/processing/features.py:1228: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  stats = torch.load(path, map_location=device)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def convert_time(secs):\n    return datetime.timedelta(seconds=round(secs))\n\ndef segment_embedding(segment, duration):\n    try:\n        audio=Audio()\n\n        start=segment[\"start\"]\n        end=min(duration, segment[\"end\"])\n\n        clip=Segment(start, end)\n        waveform, sample_rate=audio.crop(audio_file, clip)\n\n        embeddings=embedding_model(waveform[None])\n        return embeddings\n    except Exception as e:\n        traceback.print_exc()\n        raise RuntimeError(\"Error During Segment Embedding\", e)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:00.624014Z","iopub.execute_input":"2024-11-12T16:53:00.624728Z","iopub.status.idle":"2024-11-12T16:53:00.631368Z","shell.execute_reply.started":"2024-11-12T16:53:00.624683Z","shell.execute_reply":"2024-11-12T16:53:00.630376Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# load the ASR model\nwhisper_model=\"base\"\nmodel=WhisperModel(whisper_model, compute_type=\"int8\")\ntime_start=time.time()","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:00.980034Z","iopub.execute_input":"2024-11-12T16:53:00.980896Z","iopub.status.idle":"2024-11-12T16:53:05.170983Z","shell.execute_reply.started":"2024-11-12T16:53:00.980858Z","shell.execute_reply":"2024-11-12T16:53:05.169963Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.31k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118dc9b0a5354287a14e505f0ef77d2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocabulary.txt:   0%|          | 0.00/460k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"679caf0eb91f43849a7643e3e0994df6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e65e8f3601f44080a95adea16ab95ea5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d52eccdc8e489fbc5db3dbd2417917"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## ASR with Duration using Whisper¶","metadata":{}},{"cell_type":"code","source":"# get duration\naudio_data, sampling_rate=librosa.load(audio_file, mono=True, sr=16000)\nduration=len(audio_data)/sampling_rate # calculate duration\n# transcribe audio\noptions = dict(language=\"en\", beam_size=5, best_of=5)\ntranscribe_options=dict(task=\"transcribe\", **options)\nsegments_raw, info=model.transcribe(audio_file, **transcribe_options)\n\n# convert back to original format\nsegments = []\nfor segment_chunk in segments_raw:\n    chunk={}\n    chunk[\"start\"]=segment_chunk.start\n    chunk[\"end\"]=segment_chunk.end\n    segments.append(chunk)\n#     print(segment_chunk.start, segment_chunk.end, segment_chunk.text)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:05.172597Z","iopub.execute_input":"2024-11-12T16:53:05.172968Z","iopub.status.idle":"2024-11-12T16:53:24.373817Z","shell.execute_reply.started":"2024-11-12T16:53:05.172922Z","shell.execute_reply":"2024-11-12T16:53:24.372719Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Q1\nprint(len(audio_data))","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:24.375117Z","iopub.execute_input":"2024-11-12T16:53:24.375423Z","iopub.status.idle":"2024-11-12T16:53:24.380601Z","shell.execute_reply.started":"2024-11-12T16:53:24.375393Z","shell.execute_reply":"2024-11-12T16:53:24.379424Z"},"trusted":true},"outputs":[{"name":"stdout","text":"1935244\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Q2\n!ffmpeg -i /kaggle/working/TEST-1.mp3","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:24.382671Z","iopub.execute_input":"2024-11-12T16:53:24.382996Z","iopub.status.idle":"2024-11-12T16:53:25.514639Z","shell.execute_reply.started":"2024-11-12T16:53:24.382950Z","shell.execute_reply":"2024-11-12T16:53:25.513469Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n\u001b[0mInput #0, wav, from '/kaggle/working/TEST-1.wav':\n  Metadata:\n    title           : clideo.com\n    encoder         : Lavf58.76.100\n  Duration: 00:02:00.95, bitrate: 256 kb/s\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n\u001b[4;31mAt least one output file must be specified\n\u001b[0m","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Q3, channel type\n!ffmpeg -i /kaggle/working/TEST-1.mp3","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:25.516324Z","iopub.execute_input":"2024-11-12T16:53:25.516767Z","iopub.status.idle":"2024-11-12T16:53:26.639155Z","shell.execute_reply.started":"2024-11-12T16:53:25.516718Z","shell.execute_reply":"2024-11-12T16:53:26.637976Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n\u001b[0mInput #0, wav, from '/kaggle/working/TEST-1.wav':\n  Metadata:\n    title           : clideo.com\n    encoder         : Lavf58.76.100\n  Duration: 00:02:00.95, bitrate: 256 kb/s\n  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n\u001b[4;31mAt least one output file must be specified\n\u001b[0m","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Q6\nlen(segments)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:26.642086Z","iopub.execute_input":"2024-11-12T16:53:26.642994Z","iopub.status.idle":"2024-11-12T16:53:26.650340Z","shell.execute_reply.started":"2024-11-12T16:53:26.642927Z","shell.execute_reply":"2024-11-12T16:53:26.649186Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"35"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Q7\nembedding_model.dimension","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:26.651688Z","iopub.execute_input":"2024-11-12T16:53:26.652029Z","iopub.status.idle":"2024-11-12T16:53:28.209166Z","shell.execute_reply.started":"2024-11-12T16:53:26.651985Z","shell.execute_reply":"2024-11-12T16:53:28.208220Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"192"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Q8\nprint(len(model.supported_languages))","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:28.210483Z","iopub.execute_input":"2024-11-12T16:53:28.210838Z","iopub.status.idle":"2024-11-12T16:53:28.215749Z","shell.execute_reply.started":"2024-11-12T16:53:28.210801Z","shell.execute_reply":"2024-11-12T16:53:28.214903Z"},"trusted":true},"outputs":[{"name":"stdout","text":"100\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Embeddings for segments with SpeechBrain","metadata":{}},{"cell_type":"code","source":"embeddings = np.zeros(shape=(len(segments),192))\nprint(embeddings.shape)\nfor i, segment in enumerate(segments):\n    embeddings[i]=segment_embedding(segment, duration)\nembedddings=np.nan_to_num(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:53:28.216822Z","iopub.execute_input":"2024-11-12T16:53:28.217138Z","iopub.status.idle":"2024-11-12T16:53:29.161230Z","shell.execute_reply.started":"2024-11-12T16:53:28.217107Z","shell.execute_reply":"2024-11-12T16:53:29.160283Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(35, 192)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Apply the Clustering Algorithm","metadata":{}},{"cell_type":"code","source":"best_num_speaker=3\nclustering = KMeans(best_num_speaker, random_state=42).fit(embeddings)\nlabels=clustering.labels_\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:54:14.951095Z","iopub.execute_input":"2024-11-12T16:54:14.951633Z","iopub.status.idle":"2024-11-12T16:54:15.012695Z","shell.execute_reply.started":"2024-11-12T16:54:14.951576Z","shell.execute_reply":"2024-11-12T16:54:15.011162Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1], dtype=int32)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"c_1, c_2, c_3 = clustering.cluster_centers_","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:54:16.794491Z","iopub.execute_input":"2024-11-12T16:54:16.794893Z","iopub.status.idle":"2024-11-12T16:54:16.799474Z","shell.execute_reply.started":"2024-11-12T16:54:16.794853Z","shell.execute_reply":"2024-11-12T16:54:16.798572Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import numpy as np\n\ndef euclidean_distance(array1, array2):\n    # Ensure the arrays are NumPy arrays\n    array1 = np.array(array1)\n    array2 = np.array(array2)\n    \n    # Check if the arrays have the same shape\n    if array1.shape != array2.shape:\n        raise ValueError(\"Arrays must have the same shape\")\n    \n    # Calculate the Euclidean distance\n    distance = np.sqrt(np.sum((array1 - array2) ** 2))\n    return distance\n","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:54:17.711391Z","iopub.execute_input":"2024-11-12T16:54:17.711777Z","iopub.status.idle":"2024-11-12T16:54:17.717358Z","shell.execute_reply.started":"2024-11-12T16:54:17.711740Z","shell.execute_reply":"2024-11-12T16:54:17.716478Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Q9\nd_12 = euclidean_distance(c_1, c_2)\nprint(\"Distance between centers 1 and 2\", d_12)\nd_13 = euclidean_distance(c_1, c_3)\nprint(\"Distance between centers 1 and 3\", d_13)\nd_23 = euclidean_distance(c_2, c_3)\nprint(\"Distance between centers 2 and 3\", d_23)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:54:18.467274Z","iopub.execute_input":"2024-11-12T16:54:18.467653Z","iopub.status.idle":"2024-11-12T16:54:18.474234Z","shell.execute_reply.started":"2024-11-12T16:54:18.467617Z","shell.execute_reply":"2024-11-12T16:54:18.473169Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Distance between centers 1 and 2 303.5204511724629\nDistance between centers 1 and 3 341.6032296573219\nDistance between centers 2 and 3 247.53708017036368\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"best_num_speaker=2\nclustering = KMeans(2, random_state=42).fit(embeddings)\nlabels=clustering.labels_\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-11-12T16:54:19.256657Z","iopub.execute_input":"2024-11-12T16:54:19.257023Z","iopub.status.idle":"2024-11-12T16:54:19.278505Z","shell.execute_reply.started":"2024-11-12T16:54:19.256989Z","shell.execute_reply":"2024-11-12T16:54:19.277654Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"! pip install moviepy pandas pillow -q","metadata":{"id":"Es2hTTySN87G","execution":{"iopub.status.busy":"2024-11-12T16:54:20.516207Z","iopub.execute_input":"2024-11-12T16:54:20.516624Z","iopub.status.idle":"2024-11-12T16:54:32.980531Z","shell.execute_reply.started":"2024-11-12T16:54:20.516588Z","shell.execute_reply":"2024-11-12T16:54:32.979361Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\nfrom moviepy.editor import VideoFileClip, ImageClip, CompositeVideoClip\nfrom PIL import Image, ImageDraw, ImageFont\n\ndf_results = transcription_results\n\n# Step 4: load the video\n\nvideo_path=\"/content/videoplayback.mp4\" # update with oyur video path\nvideo = VideoFileClip(video_path)\n\n# functions to create an image with text\n\ndef create_text_image(text, font_size=70, img_size=(640, 80), bg_color=(0,0,0), text_color=(255,255,255)):\n    img=Image.new(\"RGB\", img_size, color=bg_color)\n    d = ImageDraw.Draw(img)\n\n    try:\n        font=ImageFont.truetype(\"arial.ttf\", font_size)\n    except IOError:\n        font = ImageFont.load_default()\n    text_width, text_height=d.text_size(text, font=font)\n    position = ((img[0]-text_width)/2, (img_size[1]-text_height)/2)\n    d.text(position, text, fill=text_color, font=font)\n    return img\n\n# Step 5: Overlay Speaker Labels\n\nclips = [video]\n\nfor _, row in df_results.iterrows():\n    start_time = pd.to_datetime(row[\"Start\"]).time()\n    end_time = pd.to_datetime(row[\"End\"]).time()\n\n    start_seconds=start_time.hour * 3600 + start_time.minute * 60 + start_time.second\n    end_seconds=end_time.hour * 3600 + end_time.minute * 60 + end_time.second\n\n    text_img = create_text_image(row[\"Speaker\"])\n    text_img_path=\"/content/temp_text_img.png\"\n    text_img.save(text_img_path)\n\n    txt_clip = (ImageClip(text_img_path)\n                .set_position('center', 'bottom')\n                .set_start(start_seconds)\n                .set_duration(end_seconds-start_seconds))\n\n    clips.append(txt_clip)\n\n# Combine All Clips\n\nfinal_video=CompositeVideoClip(clips)\n\nfinal_video_path = \"/content/videoplayback_label.mp4\"\nfinal_video.write_videofile(final_video_path, codec=\"libx264\")","metadata":{"id":"upd_bAOdgvsB"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import HTML\nfrom base64 import b64encode\n\ndef show_video(final_video_path, video_width=1000):\n\n    video_file = open(final_video_path, \"r+b\").read()\n\n    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n\n    return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n\nshow_video(final_video_path)","metadata":{"id":"fAppBB_mSPYs"},"outputs":[],"execution_count":null}]}